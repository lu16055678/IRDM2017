<html>
 <head> 
  <title>Novel methods for global minimisation
</title> 
 </head> 
 <body text="#000000" bgcolor="#FFFFFF" link="#336666" alink="#336666" vlink="#336666"> 
  <table width="900" cellspacing="15" cellpadding="5"> 
   <tbody>
    <tr> 
     <td> <font color="#000000" face="Arial, Helvetica, sans-serif"> <font size="+2"><font color="#006699"> <strong> Novel methods for global minimisation </strong> </font></font> <p> </p>
       <hr> <p> Many important problems in engineering and technology involve finding the highest (optimisation) or lowest (minimisation) point on a complex surface, one possibly of very high dimension. (These two problems are basically the same since an optimisation problem can be turned into one of minimisation by just multiplying all the heights on the surface that needs to be ascended by -1.) What makes the problem of minimisation hard is that these surfaces are usually covered with valleys and basins (<i>local minima</i>) as well as the deeper well that surrounds the lowest point (<i>global minimum</i>) that one is trying to reach, and the classical algorithms for finding the lowest point on a surface only in practice find the lowest point in the neighbourhood of where one started -- which may be a much higher value than the global minimum being searched for. Two areas where the problem of finding a global minimum has been the subject of much work are in <i>neural network training</i> (where the surface to be descended describes the error associated with the network's behaviour for a particular set of 'weight' values) and <i>protein structure prediction</i> (trying to predict what 3-dimensional shape a protein molecule will adopt, given only the 1-dimensional sequence of amino acids within it, with points on the surface here representing the internal energy of a structural configuration as a function of protein chain geometry). </p><p> </p>
       <hr> <p> <font size="+1"> <strong> <a href="http://www.cs.ucl.ac.uk/staff/D.Gorse/research/ERA.html"> The ERA method for training neural networks</a> </strong> </font> </p><p> This is a form of <i>smoothing method</i> (the surface is simplified to remove small local basins that could trap the descent algorithm, the lowest point of that smoothed surface is found, then the original complexity of the surface is gradually recovered with the hope that the global minimum will be tracked throughout); there have been many such algorithms proposed in the past, but the ERA method is an especially easy one to implement in the neural network context. </p><p> </p>
       <hr> <p> <font size="+1"> <strong> <a href="http://www.cs.ucl.ac.uk/staff/D.Gorse/research/chap.html"> Chaperone-based methods for global minimisation of protein energy functions</a> </strong> </font> </p><p> In this application the surface manipulation method does not just smooth out the original shape but transforms it in a particular way, based on what is known about how some proteins fold within the cell, needing other 'helper' molecules referred to as <i>chaperones</i>. The hypersurface transformation used in this work initially untangles energetically unfavourable regions in the protein structure before changing its form to then encourage movement into regions of the energy surface from which finding the global minimum is much easier. Results obtained using these methods were very encouraging, and suggested hypersurface deformation ideas derived from the chaperonin systems might be a useful tool for finding nativelike structures of proteins and protein-like heteropolymer systems. </p><p> </p>
       <hr> </font></td> 
    </tr> 
   </tbody>
  </table>    
 </body>
</html>